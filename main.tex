\RequirePackage{fix-cm}
\PassOptionsToPackage{svgnames}{xcolor}
\documentclass[10pt]{beamer}
\usepackage{adjustbox}

\usetheme{Madrid}
\usecolortheme{default}
\definecolor{moderncvgreen}{rgb}{0.35,0.70,0.30}
\colorlet{beamer@blendedblue}{moderncvgreen}
% \setbeamercovered{transparent}

\makeatletter
\newcommand\HUGE{\@setfontsize\Huge{50}{60}}
\makeatother

\usepackage{tikzpeople}
\usepackage{fontawesome5}
\usepackage{animate}

\usepackage{tikz}
\usetikzlibrary{shapes,positioning,calc,arrows.meta,decorations.pathmorphing,patterns,decorations, decorations.markings,arrows, shapes.geometric,fit,patterns.meta,3d,decorations.pathreplacing,arrows.meta,graphs,graphdrawing}
\usegdlibrary{force}
\usetikzlibrary{pgfplots.groupplots}

\usepackage{pgfplots}
\pgfplotsset{compat = newest}
\usetikzlibrary{overlay-beamer-styles}
% \pgfplotsset{width=7cm,compat=1.16}

\definecolor{DarkPurple}{HTML}{9467BD}
\definecolor{DarkOrange}{HTML}{FF8C00}
\definecolor{Kaki}{HTML}{BCBD22}
\definecolor{CommunityA}{HTML}{EE7993} % Pinkish-red
\definecolor{CommunityB}{HTML}{3FB17D} % Green

% \usetikzlibrary{arrows}
% \RequirePackage{fix-cm}
% \usepackage{tikz-cd}

\usepackage{tabularx}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{booktabs}

% \tikzset{
%   font={\fontsize{7pt}{9}\selectfont}}

 \usepackage{subcaption}
 \usepackage{amsmath,bm,amssymb}
 \usepackage{bbm}
 \DeclareMathOperator*{\argmax}{arg\,max}
 \DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{hyperref}

\usepackage[backend=biber, style=authoryear, sortcites=false, uniquelist=false,natbib=true,doi=false,isbn=false,url=false,eprint=false,pagetracker, ibidtracker=constrict]{biblatex}
\DefineBibliographyExtras{french}{\restorecommand\mkbibnamefamily}
\AtEveryBibitem{\clearfield{entrysubtype}}
\AtEveryBibitem{\clearfield{pages}}
\renewcommand*{\nameyeardelim}{\addcomma\addspace}
\addbibresource{references.bib}
\renewcommand*{\bibfont}{\normalfont\fontsize{8}{10}\selectfont}

% \newcommand\Wider[2][3em]{%
% \makebox[\linewidth][c]{%
%   \begin{minipage}{\dimexpr\textwidth+#1\relax}
%   \raggedright#2
%   \end{minipage}%
%   }%
% }


%------------------------------------------------------------
%This block of code defines the information to appear in the
%Title page
\title[Inverse Problems for Philosophers] %optional
{
Inverse Problems for Philosophers
}
\subtitle{Bridging the gap between agent-based models and behavioral data}

\author[L.~Gautheron]
{Lucas~Gautheron
\\\texttt{lucasgautheron.github.io}
}

\institute[IZWT, ENS] % (optional)
{
  %
  Interdisciplinary Center for Science and Technology Studies, Wuppertal\\
  ~\\
  École Normale Supérieure, Paris
}

\date[24/01/2025] % (optional)
{University of Bochum, January 2025}

%\logo{\includegraphics[height=1cm]{overleaf-logo}}

%End of title page configuration block
%------------------------------------------------------------



%------------------------------------------------------------
%The next block of commands puts the table of contents at the 
%beginning of each section and highlights the current section:

\addtobeamertemplate{title page}{
  \begin{tikzpicture}[remember picture,overlay]
    \node[above right,inner sep=0pt,opacity=0.85] at (current page.south west)
    {
    \includegraphics[width=1.1\paperwidth]{snow.jpg}
    };
  \end{tikzpicture}
}{}

\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Summary}

    % \textbf{Goal: understanding how the field of High-Energy physics adapts as a major research program loses its empirical support and content}
    \tableofcontents[currentsection]
  \end{frame}
}

% \AtBeginSubsection[]
% {
%   \begin{frame}
%     \frametitle{Summary}

%     % \textbf{Goal: understanding how the field of High-Energy physics adapts as a major research program loses its empirical support and content}
%     \tableofcontents[currentsection,currentsubsection]
%   \end{frame}
% }


\AtBeginSubsection[]
{
  \begin{frame}
    \tableofcontents[currentsubsection]
  \end{frame}
}


\begin{document}


%The next statement creates the title page.
\frame{
\titlepage
}

\begin{frame}{Summary}
    \tableofcontents
\end{frame}

\begin{frame}{Why should philosophers care about data?}
Reasons are:
    \begin{itemize}
        \item<1-> \textbf{Intellectual}: assess whether models capture what is actually going on in situations of interest / use data as a source of inspiration
        \item<2-> \textbf{Methodological}: Non-empirical validation is fallible. Example: ``robustness'' (insensitivity to model assumptions/parameters) $\Rightarrow$ what if the outcome really is contingent on certain circumstances (the values of underlying parameters, the topology of some relevant network, etc.)
        \item<3-> \textbf{Practical}: normative insights from models without connection to data may not be translatable into interventions/policies (abstract parameters in a computational model do not immediately connect to actionable parameters!)
        % \item<4-> \textbf{Ethical}: un-validated models should maybe not provide guidance for policy-making.
    \end{itemize}
\end{frame}

% \begin{frame}{Empirical agent-based models}

%     Micro-level observations: missing
%     Macro observations

%     \vspace{1em}
%     \uncover<2->{
%         $\Rightarrow$ \textbf{Inverse problems} are a promising candidate for bridging the formal/empirical gap.
%     }
% \end{frame}

\section{Inverse problems for philosophers and agent-based modelers}

\begin{frame}{What are inverse problems}
    \begin{itemize}
        \item<1-> Inverse problems seek to \textbf{infer the invisible causes underlying a set of observations}.
        \item<2-> In the context of Agent-Based Modeling:
    \end{itemize}

    \uncover<2->{
    \begin{figure}
        \centering
        \begin{tikzpicture}
        \node[align=center] at (-2,0) {Rules governing\\agents' behavior};
        \draw[->] (0, 0.25) -- (4, 0.25) node[midway, above] {``\textcolor{blue}{Forward problem}''};
        \draw[<-,visible on=<3->] (0, -0.25) -- (4, -0.25) node[midway, below] {``\textcolor{red}{Inverse problem}''};
        \node[align=center] at (+6,0) {Outcome of\\agents' behavior};
        \end{tikzpicture}
    \end{figure}}

    \begin{itemize}
        \item<4-> Inverse problems are \textbf{hard}:
        \begin{enumerate}
            \item<5-> \textbf{Identifiability problems} (underdetermination): many causes could have produced a given outcome
            \item<6-> \textbf{Misspecification problems}: inverse problems may produce misleading results when modeling assumptions are ``too wrong''.
            \item<7-> \textbf{Computational problems}: solving inverse problems often involves intractable computations and requires approximation schemes.
        \end{enumerate}
    \end{itemize}
\end{frame}

\begin{frame}{Bayesian inference for inverse problems}
    \begin{itemize}
        \item Both forward models and inverse problems have a stochastic/probabilistic component (\textcolor{blue}{random initialization, partially random decisions}; \textcolor{red}{uncertainty quantification}\dots)
        \item We appeal to \textbf{probabilities} and \textbf{Bayesian inference}.
    \end{itemize}

    \begin{figure}
        \centering
        \begin{tikzpicture}
        \node[align=center] at (-2,0) {Rules governing\\agents' behavior\\\textbf{Model} $\bm{M}$};
        \draw[->] (0, 0.25) -- (4, 0.25) node[midway, above, align=center] {``\textcolor{blue}{Forward problem}''\\Estimate $\textcolor{blue}{\bm{P(O|M)}}$};
        \draw[<-] (0, -0.25) -- (4, -0.25) node[midway, below, align=center] {``\textcolor{red}{Inverse problem}''\\Estimate $\textcolor{red}{\bm{P(M|O)}}$};
        \node[align=center] at (+6,0) {Outcome of\\agents' behavior\\\textbf{Outcome} $\bm{O}$};
        \end{tikzpicture}

        \begin{equation}
            \textcolor{red}{P(M|O)} = \dfrac{\textcolor{blue}{P(O|M)}\overbrace{P(M)}^{\text{Prior}}}{P(O)}
        \end{equation}
    \end{figure}
\end{frame}

\begin{frame}{Model comparison and parameter estimation}
    \only<1>{
    \begin{equation}
        \textcolor{red}{P(M|O)} = \dfrac{\textcolor{blue}{P(O|M)}\overbrace{P(M)}^{\text{Prior}}}{P(O)}
    \end{equation}}
    \only<2>{
    \begin{equation}
        \textcolor{red}{P(\theta|O)} = \dfrac{\textcolor{blue}{P(O|\theta)}\overbrace{P(\theta)}^{\text{Prior}}}{P(O)}
    \end{equation}
    }
\end{frame}

\section{A case-study of conventions: the metric signature in particle physics}


\begin{frame}{Conventions}
    \begin{itemize}
        \item<1-> \textbf{Coordination problems} arise when individuals would benefit from acting in a mutually compatible way, but it is somehow non-trivial to do so \citep{Lewis2002}.
        \begin{figure}
        \begin{tikzpicture}
    % Alice
    \node[alice, minimum size=0.8cm] (alice) at (0,0) {};
    % \node at (0,-1.5) {Alice};

    % Bob
    \node[bob, minimum size=0.8cm] (bob) at (4,0) {};
    % \node at (4,-1.5) {Bob};

    % Phone in the middle
    \node at (2,0) {\faPhone[regular,scale=1.5]};

    % Curly line between Alice and Bob
    \draw[thick, decorate, decoration={snake, amplitude=1mm, segment length=4mm}] 
        (alice.east) -- (1.5,0);
    \draw[thick, decorate, decoration={snake, amplitude=1mm, segment length=4mm}] 
        (2.5,0) -- (bob.west);
    \node[red,visible on=<2->] at (2,0) {\Huge $\times$}; % Red cross in the middle

\end{tikzpicture}

        %     \begin{tikzpicture}
        %         \node[inner sep=0pt,visible on=<1->] (phone) at (0,0)
        % {\includegraphics[width=0.4\textwidth]{presentations/phone.jpg}};
        %         \node[color=red,visible on=<2->] (test) at (0, -0.65) {\HUGE{$\bm{\times}$}};
        
        %     \end{tikzpicture}
        \end{figure}

        \uncover<3->{
            \begin{table}[]
\resizebox{0.5\columnwidth}{!}{%
\begin{tabular}{l|c|c|}
\cline{2-3}
                                                & \textbf{\begin{tabular}[c]{@{}c@{}}Bob\\ calls back\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Bob\\ awaits\end{tabular}} \\ \hline
\multicolumn{1}{|l|}{\textbf{Alice calls back}} & 0,0                                                                 & 1,1                                                            \\ \hline
\multicolumn{1}{|l|}{\textbf{Alice awaits}}      & 1,1                                                                 & 0,0                                                            \\ \hline
\end{tabular}%
}
\end{table}
        }
        
        \item<4-> \textbf{``Conventions''} are cultural tools for solving coordination problems by providing individuals with expectations about how others will behave. These expectations suggest particular courses of action.
        \begin{itemize}
            \item<5-> Example: left-hand or right-hand traffic.
            \item<6-> Language! ``The syllable `big' could have meant `small' for all we care, and the red light could have meant `go''' (Quine, foreword to \citealt{Lewis2002})
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Conventions in the literature}
\begin{itemize}
    \item<1-> Generally based on Lewis: conventions as solutions to coordination games \citep{Lewis2002}
    \begin{enumerate}
        \item<2-> Can conventions emerge spontaneously from dyadic interactions alone? \citep{Centola2015,hawkins2019emergence}
        \item<3-> How does the topology of social networks influence the propagation of conventions via dyadic interactions? \citep{pujol2005role,delgado2002emergence}
        \item<4-> How to measure the degree of conventionality of a convention? \citep{OConnor2020}
        % \item<5-> What is the role of leadership in addressing coordination problems? \citep{calvert1992leadership}
    \end{enumerate}

    \uncover<5->{Most often: idealized formal models or controlled experiments. Few studies in naturalistic settings!}
\end{itemize}
% \begin{itemize}
%     \item Theoretical papers ([evolutionary] game theory, agent-based modeling, e.g. on complex networks\dots)
%     \item Experimental setups.
%     \item Observational analyses of behavioral data (e.g. Twitter data).
% \end{itemize}
\end{frame}

\begin{frame}{A case-study from high-energy physics}
    \begin{itemize}
        \item<1-> Relativistic theories: unified description of spacetime.
        \item<2-> The metric tensor ($g_{\mu\nu})$ captures the metric properties of spacetime; e.g. the pseudo- distance between events $(t_1,x_1,y_1,z_1)$ and $(t_2,x_2,y_2,z_2)$. \textbf{Two possible descriptions} (metric signatures):
    \end{itemize}
    
    \vspace{1em}

    \uncover<3->{
        \begin{equation*}
            \begin{pmatrix}
            +1 & 0 & 0 & 0\\
            0 & -1 & 0 & 0\\
            0 & 0 & -1 & 0\\
            0 & 0 & 0 & -1\\
            \end{pmatrix} \text{ or } \begin{pmatrix}
            -1 & 0 & 0 & 0\\
            0 & +1 & 0 & 0\\
            0 & 0 & +1 & 0\\
            0 & 0 & 0 & +1\\
            \end{pmatrix} ?
        \end{equation*}
    }

    % \uncover<4->{
    %     \begin{equation}
    %         \scriptsize{\Delta s^2 = (t_2-t_1)^2-(x_2-x_1)^2-\dots \text{ or } \Delta s^2 = -(t_2-t_1)^2 +(x_2-x_1)^2+ \dots}
    %     \end{equation}
    % }

    \uncover<4->{
        \begin{equation}
            \text{``mostly minus'' (-1) or ``mostly plus'' (+1)}
        \end{equation}
    }

    \begin{itemize}
        \item<5-> Both choices are legitimate, as long as one remains consistent.
    \end{itemize}
\end{frame}


\begin{frame}{A heated debate}
    \centering
    \begin{tikzpicture}
        \node[inner sep=0pt,visible on=<1->] (meme1) at (0,0)
    {\includegraphics[width=0.55\textwidth]{presentations/meme1.png}};
        \node[inner sep=0pt,visible on=<2->] (meme2) at (2,0)
    {\includegraphics[width=0.45\textwidth]{presentations/meme2.png}};
        \node[inner sep=0pt,visible on=<3->] (meme3) at (0,-2.5)
    {\includegraphics[width=0.45\textwidth]{presentations/meme3.png}};
        \node[inner sep=0pt,visible on=<4->] (meme4) at (-2.5,0)
    {\includegraphics[width=0.45\textwidth]{presentations/meme4.png}};
        \node[inner sep=0pt,visible on=<5->] (meme5) at (0,1.5)
    {\includegraphics[width=0.45\textwidth]{presentations/meme5.png}};
    \end{tikzpicture}
\end{frame}

\begin{frame}{Inverse problems and conventions}
    \begin{itemize}
        \item<1-> Let's use inverse problems to infer:
        \begin{enumerate}
            \item<2-> How do scientists decide which convention to use in a paper?
            \item<3-> How do they resolve conflicting preferences in collaborations?
            \item<4-> What factors shape scientists' preferences?
        \end{enumerate}
    \end{itemize}
\end{frame}

\begin{frame}{Data}
    \begin{itemize}
        \item Data collected from \textbf{Inspire HEP} (authorship/citation metadata) and \textbf{arXiv} (LaTeX source)
        \item Categories: hep-th (high-energy physics theory), hep-ph (phenomenology), gr-qc (gravitation and cosmology), astro-ph (astrophysics)
        \item 22\,500 papers classified according to their metric signature (mostly plus or mostly minus) using regular expressions.
    \end{itemize}
\end{frame}

% \section{Three trade-offs involved in the propagation of conventions}

% \begin{frame}{Trade-offs involved in the diffusion of scientific conventions}
%     \begin{itemize}
%         \item[(A)] Trade-off between \textbf{coordination costs, inconsistency costs, and maladaptation costs}
%         \item[(B)] The competition between \textbf{local and global mechanisms of coordination}
%         \item[(C)] The trade-off between \textbf{decision-optimality} (e.g. collective satisfaction maximization) and \textbf{decision costs}, in the context of the resolution of conflicts.
%     \end{itemize}    
% \end{frame}

\subsection{How do physicists choose which convention to use in their own papers?}

\begin{frame}{How do physicists choose which convention to use in their own papers?}
Individuals' attitude towards a convention may be shaped by:

    % \begin{enumerate}
    %     \item<2-> \textbf{Social consistency} (driven by coordination costs).
    %     \item<3-> \textbf{Individual consistency} (driven by switching costs).
    %     \item<4-> \textbf{Contextual consistency} (the ``maladaptation'' cost of using a convention that is a poor fit/suboptimal in a given context) $\Rightarrow$ degrees of conventionality \citep{OConnor2020}
    % \end{enumerate}

    \begin{figure}
        \centering
        \resizebox{0.95\textwidth}{!}{\input{tradeoffs}}
    \end{figure}

    \uncover<2->{$\Rightarrow$ Are these involved in the context of the metric signature? }
\end{frame}

\begin{frame}{Individual and contextual consistency}
\vspace{-1em}
\def\alice{\tikz[baseline=-.2ex]{
\node[alice] at (0,0) {};}
}

\begin{itemize}
    \item \alice publishes $d$ in category $c_d \in \{\text{phenomenology, theory, \dots}\}$. What determines which convention she uses? Our assumption:
\end{itemize}

\begin{columns}
    \begin{column}{0.67\textwidth}
    \begin{equation*}
    \small P(\sigma_d=+1|\textcolor{DarkPurple}{\theta(\alice)},\textcolor{Kaki}{b(c_d)}) = f(\textcolor{DarkPurple}{\underbrace{\bm{\theta}(\alice)}_{\substack{\text{Author's}\\\text{preference}}}}+\textcolor{Kaki}{\underbrace{b(c_d)}_{\substack{\text{Effect of}\\\text{research area}}}})% = \frac{e^{+\frac{1}{2}(\textcolor{red}{\theta_i}+\textcolor{blue}{b_c})}}{e^{+\frac{1}{2}(\textcolor{red}{\theta_i}+\textcolor{blue}{b_c})}+e^{-\frac{1}{2}(\textcolor{red}{\theta_i}+\textcolor{blue}{b_c})}}
    \end{equation*}
    \end{column}
    \begin{column}{0.33\textwidth}
    \vspace{-0.75em}
    \begin{tikzpicture}
    \begin{axis}[
            xmin=-2, xmax=+2, % x scale
            ymin=0, ymax=1, % y scale
            domain=-2:2,  % added, key improvements
            scale only axis=true,
            width=0.85\textwidth,
            height=0.45\textwidth,
            clip=false
            % enlarge x limits=false,
            % enlarge y limits=false
    ]
    \addplot[smooth, black]    {exp(x)/(exp(x)+exp(-x))};
    \draw[->,color=DarkPurple, line width=0.5mm] (0,0) -- (0.9,0) node[midway, above, color=DarkPurple] {$\bm{\theta}$};
    \draw[->,color=Kaki, line width=0.5mm] (0.9,0) -- (1.3,0)  node[midway, above, color=Kaki] {$\bm{b}$};
    \draw[dashed] (1.3,0) -- (1.3,0.93);
    \draw[dashed] (-2,0.93) -- (1.3,0.93);
    \end{axis}
    \end{tikzpicture}
    \end{column}
\end{columns}

\begin{itemize}
    \item<2-> $\textcolor{DarkPurple}{\theta(i)}=\pm \mu$ is a latent (unobserved) parameter measuring the preference of each author $i$. $\textcolor{DarkPurple}{\theta(i)}>0$ indicates a preference for the mostly plus signature
    \item<3-> $\textcolor{Kaki}{b_c}$ is the unobserved bias associated with research area $c$
    \item<4-> If $|\textcolor{DarkPurple}{\theta}|\gg |\textcolor{Kaki}{b}|$, individual preferences dominate the need to adapt to a given research area
    \item<5-> ``Item-response model'': recover invisible traits/factors that may account for observed behaviors.
    \item<6-> \textbf{Given physicists' choices in their solo-authored papers, we can infer back $\theta$ and $b$ using Bayesian inference}.
\end{itemize}
\end{frame}

\begin{frame}{Individual and contextual consistency}
\vspace{-1em}
\begin{figure}
\centering
\includegraphics[width=0.5\linewidth]{consistency_vs_task_simple.pdf}
    \vspace{-0.75em}
    \caption{Individual consistency (preferences) matter the most, but adaptation to the context also occurs.}
\end{figure}
\end{frame}

\begin{frame}{Individual and contextual consistency}
\begin{figure}
\centering
\includegraphics[width=0.5\linewidth]{preferences.pdf}
    \caption{Physicists tend to always be using the same convention}
\end{figure}
\end{frame}

\subsection{How do scientists resolve conflicting preferences in collaborations?}

% \begin{frame}{Decision optimality and decision costs in the resolution of conflicts}
%     \begin{itemize}
%         \item In scientific collaborations, the resolution of disagreement involves two factors:
%         \item[1] The ``optimality'' of the decision (i.e., truth-value -- if relevant --, collective satisfaction, appropriateness of the solution etc.).
%         \item[2] The cost of reaching an ``optimal'' decision.
%         \item Leadership is a tool for reducing ``transaction'' and decision costs in organizations \citep{calvert1992leadership}. Does it play a similar role in the case of the metric signature?
%     \end{itemize}
% \end{frame}

\begin{frame}{Inferring preference-aggregation mechanisms in conflicts}
How scientists resolve conflicting preferences in collaborations?

    \begin{itemize}
        \item<2-> Focusing on co-authored papers for which:
        \begin{enumerate}
            \item<3->[(i)] The metric signature $S_d\in\{-1,+1\}$ of the paper is observed
            \item<4->[(ii)] The preference of each author $(\sigma_1, \dots, \sigma_n)\in \{\pm 1\}^n$ is known independently from at least one solo-authored publication
            % \item[(iii)] At least two co-authors have conflicting preferences ($\exists i,j | \sigma_i \neq \sigma_j$).
        \end{enumerate}
        \item<5-> We can assume different preference aggregation strategies ($A_k$):
        \begin{itemize}
            \item<6-> Dictatorial strategies (the first author, the last author, or another author decides)
            \item<7-> Majoritarian strategy (the majority preference prevails)
            \item<8-> Conventional strategy (the signature most common in the target research area prevails)
            \item<9-> Random/coin-flip (both individual preferences and context are ignored)
        \end{itemize}
        \item<10-> We can estimate the prevalence of each strategy ($\pi_k$) given that they predict different outcomes (different probabilities  $P(S_d|\sigma_1,\dots,\sigma_n,A_k)$)
    \end{itemize}
\end{frame}

\begin{frame}{Inferring preference-aggregation mechanisms}
    Each paper brings a bit more information about $\pi_k$, the prevalence of an aggregation strategy $A_k$.
        
    \foreach \x in {0,...,40} {
        \newcommand\frameno{\x+1}
        \only<\x>{
            \centering
            \begin{figure}
                \centering
                \includegraphics[width=0.825\linewidth]{aggregation/aggregation_frame_\x.pdf}
            \end{figure}
        }
    }
\end{frame}

\begin{frame}{Prevalence of each preference-aggregation strategy}
    
    \begin{figure}
        \centering
        \includegraphics[width=0.8\linewidth]{aggregation.pdf}
    \end{figure}
\end{frame}

\subsection{How do physicists' preferences get formed?}

\begin{frame}{Authors' preferences}
\begin{columns}
    \begin{column}{0.65\textwidth}
        \vspace{-1em}
        \begin{figure}[!h]
        \centering\includegraphics[width=0.9\textwidth,trim=250 350 225 350,clip]{authors_network.pdf}
        \end{figure}
    \end{column}
    \begin{column}{0.35\textwidth}
        \centering
        Observed outcome: the preference of each author,

        \vspace{1em}
        
        $O_{\text{obs}}=(\sigma_1,\dots,\sigma_n), \sigma \in \{\textcolor[HTML]{EE7993}{-1},\textcolor[HTML]{3FB17D}{+1}\}$

        \vspace{1em}

        ($n=2\,277$ authors)
    \end{column}
\end{columns}
\end{frame}

\begin{frame}{How do physicists' preferences get formed?}

\begin{itemize}
    \item Let's assume three models of the formation of physicists' preference towards the convention:
    \begin{enumerate}
        \item A \textbf{``strategic agent'' model} ($M_1$) assuming that individuals navigate three costs (coordination costs, inconsistency costs, and maladaptation costs) depending on their collaborators' preferences and the research areas in which they publish.
        \item A \textbf{global cultural transmission model} ($M_2$), in which physicists settle once and for all for a specific convention with a certain probability that depends on their primary research area (textbooks?)
        \item A \textbf{local cultural transmission model} ($M_3$), in which physicists copy the preference of their first collaborator.
    \end{enumerate}
    \item Which of these is more plausible given the observed patterns of preferences?
    % \item We can simulate the processes and measure the magnitudes of local and global coordination that they predict, $P(J,\bm{B}|M)$ and see which of them are consistent with the data!
\end{itemize}
\end{frame}

\begin{frame}{Example: the strategic agent model ($M_1$)}
    The model $M_1$ has multiple unknown parameters:
    \begin{itemize}
        \item $c_s$: the cost of switching from one convention to another
        \item $c_c$: the cost of disagreeing with co-authors
        \item $c_{r}$ the cost of using a suboptimal convention in a given research area
    \end{itemize}

    \vspace{0.5em}

    The \textbf{outcome} $O_{\text{sim}}$ is the joint value of each author's preference: $O_{\text{sim}}=(\sigma_1,\dots,\sigma_n)$ where $\sigma_i = \pm 1$

    % \foreach \x in {0} {
    %     \newcommand\frameno{\x+1}
    %     \only<\x>{
    %         \centering
    %         \begin{figure}
    %             \centering
    %             \includegraphics[width=0.55\linewidth]{strategic/step_J_\x.pdf}
    %         \end{figure}
    %     }
    % }
    \uncover<2->{
    \begin{figure}
        \centering
        \includegraphics[width=0.55\linewidth]{strategic/step_J_2.pdf}
    \end{figure}}
\end{frame}


\begin{frame}{Simulation-based inference}
\vspace{-0.5em}

    \begin{equation}
        \textcolor{red}{P(M_1|O)} = \textcolor{blue}{\overbrace{P(O|M_1)}^{\uncover<2->{\substack{\text{Unknown}\\\text{in ABMs!}}}}}\dfrac{P(M_1)}{P(O)}
    \end{equation}

\begin{tikzpicture}

% Draw the circle
\draw[visible on=<3->] (0,0) ++(180:2) arc (180:-180:2);

\begin{scope}
    \clip (-2,-2) rectangle (0,2);
    \draw[fill=purple!20,visible on=<3->] (0,0) ++(180:2) arc (180:-180:2);
\end{scope}

\begin{scope}
    \clip (0,-2) rectangle (2,2);
    \draw[fill=yellow!20,visible on=<3->] (0,0) ++(180:2) arc (180:-180:2);
\end{scope}

% Divide the circle into two halves
\draw[thick,visible on=<3->] (0,-2) -- (0,2);

% Label the two regions
\node[visible on=<3->] at (-1,-1) {$M_1$};
\node[visible on=<3->] at (1,-1) {$M_2$};

% Add the shaded region for O (rotate for more overlap with M1)
\fill[rotate=110,draw=green,thick,fill=none,visible on=<4->] plot[smooth] coordinates {
      (60:2)
      (50:0.8)
      (-20:1.2)
      (-60:2)
    } arc[radius=2,start angle=-60,end angle=60];

\begin{scope}
    \clip (-2,-2) rectangle (0,2);
    \fill[pattern=north east lines, pattern color=green,rotate=110,draw=green,thick,visible on=<4->] plot[smooth] coordinates {
          (60:2)
          (50:0.8)
          (-20:1.2)
          (-60:2)
        } arc[radius=2,start angle=-60,end angle=60];
\end{scope}

\begin{scope}
    \clip (0,-2) rectangle (2,2);
    \fill[pattern=north east lines, pattern color=green,rotate=110,draw=green,thick,visible on=<4->] plot[smooth] coordinates {
          (60:2)
          (50:0.8)
          (-20:1.2)
          (-60:2)
        } arc[radius=2,start angle=-60,end angle=60];
\end{scope}



\node[color=green!50!black,visible on=<4->] at (-0.75, 1.1) {$O$};

% Draw the formula for P(O|M1)
\node[anchor=west,visible on=<5->] at (2.5,1.5) {
    $\textcolor{blue}{P(O|M_1)} = \dfrac{\begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=purple!20] (0,0) rectangle (0.6,0.6);
        \fill[pattern=north east lines, pattern color=green] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}}{
    \begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=purple!20] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}} \simeq \dfrac{3}{5}$};

\node[anchor=west,visible on=<6->] at (2.5,0) {
    $\textcolor{blue}{P(O|M_2)} = \dfrac{\begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=yellow!20] (0,0) rectangle (0.6,0.6);
        \fill[pattern=north east lines, pattern color=green] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}}{
    \begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=yellow!20] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}} \simeq \dfrac{1}{5}$};

\node[anchor=west,visible on=<7->] at (2.5,-1.5) {
    $\textcolor{red}{P(M_1|O)} = \textcolor{blue}{P(O|M_1)}\dfrac{P(M_1)}{P(O)} = \dfrac{\begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=purple!20] (0,0) rectangle (0.6,0.6);
        \fill[pattern=north east lines, pattern color=green] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}}{
    \begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=purple!20] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}} \dfrac{\begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=purple!20] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}}{
    \begin{tikzpicture}[baseline=2pt]
        \draw[thick] (0,0) rectangle (0.6,0.6);
        \fill[pattern=north east lines, pattern color=green] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}} = \dfrac{\begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=purple!20] (0,0) rectangle (0.6,0.6);
        \fill[pattern=north east lines, pattern color=green] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}}{
    \begin{tikzpicture}[baseline=2pt]
        \draw[thick] (0,0) rectangle (0.6,0.6);
        \fill[pattern=north east lines, pattern color=green] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}}$};

\node[anchor=west,visible on=<8->] at (2.5,-3) {
    $\textcolor{red}{P(M_2|O)} = \textcolor{blue}{P(O|M_2)}\dfrac{P(M_2)}{P(O)} = \dfrac{\begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=yellow!20] (0,0) rectangle (0.6,0.6);
        \fill[pattern=north east lines, pattern color=green] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}}{
    \begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=yellow!20] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}} \dfrac{\begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=yellow!20] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}}{
    \begin{tikzpicture}[baseline=2pt]
        \draw[thick] (0,0) rectangle (0.6,0.6);
        \fill[pattern=north east lines, pattern color=green] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}} = \dfrac{\begin{tikzpicture}[baseline=2pt]
        \draw[thick,fill=yellow!20] (0,0) rectangle (0.6,0.6);
        \fill[pattern=north east lines, pattern color=green] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}}{
    \begin{tikzpicture}[baseline=2pt]
        \draw[thick] (0,0) rectangle (0.6,0.6);
        \fill[pattern=north east lines, pattern color=green] (0,0) rectangle (0.6,0.6);
    \end{tikzpicture}}$};

\foreach \x/\y in {-1.5/1.2, -1.2/0.8, -0.8/-1.5, -1.3/-0.5, -0.7/0.5} {
    \draw[fill=purple,draw=none,visible on=<3->] (\x,\y) circle (0.5mm);
}

% Add random nodes within M2 (in yellow)
\foreach \x/\y in {0.5/1.2, 1.2/0.8, 0.8/1.5, 1.3/-0.5, 0.7/0.5} {
    \draw[fill=yellow!20!orange,draw=none,visible on=<3->] (\x,\y) circle (0.5mm);
}
\end{tikzpicture}
\end{frame}

\begin{frame}{Curse of dimensionality in simulation-based inference}
    \begin{itemize}
        \item<1-> At least some simulations $O_s$ must match the observed outcome $O$, which means matching each of the 2\,277 authors' preferences at the same time!
        \item<2-> Virtually impossible ($95\%$ chance of predicting any individual preference $\sigma_i$ correctly $\Rightarrow$ $2\times 10^{-51}$ of getting all of them right at once)
        \item<3-> The data has \textit{too many dimensions} $\Rightarrow$ \textbf{``curse of dimensionality''}
        \item<4-> Solution: ``conditioning'' on \textbf{summary statistics} rather than the entire data.
        \item<5-> Summary statistics are \textbf{concise descriptions of the data} that capture essential features. e.g.:
        \begin{equation}
            m = \frac{1}{n}|\sum_{i=1}^n \sigma_i| \text{ (where } \sigma_i=\pm 1 \text{)}
        \end{equation}
    \end{itemize}

    \vspace{-0.5em}
    \centering\uncover<6->{\input{summary}}
\end{frame}

\begin{frame}{Summary statistics in simulation-based inference}
    There are two main approaches for choosing adequate summary statistics:
    \begin{enumerate}
        \item Hand-picking interpretable summary statistics based on our own intuitions.
        \item Using sophisticated methods to learn statistically optimal (but potentially un-interpretable) summary statistics. Optimal summary statistics reduce our posterior uncertainty given a fixed amount of data.
    \end{enumerate}
\end{frame}

\begin{frame}{Simulation-based inference with summary statistics}
    \foreach \x in {1,...,42} {
        \only<\x>{
            \centering
            \begin{figure}
                \centering
                \includegraphics[width=0.7\linewidth]{abc/frame_\x.pdf}
            \end{figure}
        }
    }
\end{frame}

\begin{frame}{Local versus global mechanisms of coordination}
\begin{figure}
    \centering
    \begin{tikzpicture}
        \node[circle, draw, fill=red!30] (D) at (2,2) {2};
        \node[circle, draw, fill=red!30] (E) at (2,0) {3};
        \node[circle, draw, fill=red!30] (F) at (1,1) {1};
    
        % Left graph (traditional)
        \node[circle, draw, fill=green!30] (A) at (-1,2) {4};
        \node[circle, draw, fill=green!30] (B) at (-1,0) {5};
        \node[circle, draw, fill=green!30] (C) at (0,1) {6};
    
    
        \draw (A) -- (B);
        \draw (B) -- (C);
        \draw (C) -- (A);
        \draw (D) -- (E);
        \draw (E) -- (F);
        \draw (F) -- (D);
    
        \draw (F) -- (C);

        \node[align=center] at (0.5, -1.5) {\textbf{Local coordination}};
        \node[align=center] at (0.5, -2.5) {Strategic alignment,\\imitation of peers\dots\\$\bm{J}$};
    
        % Right graph (common ancestor)
        \node[circle, draw, fill=green!30, visible on=<2->] (D1) at (8,2) {2};
        \node[circle, draw, fill=green!30, visible on=<2->] (E1) at (8,0) {3};
        \node[circle, draw, fill=green!30, visible on=<2->] (F1) at (7,1) {1};
    
        % Left graph (traditional)
        \node[circle, draw, fill=green!30, visible on=<2->] (A1) at (5,2) {4};
        \node[circle, draw, fill=green!30, visible on=<2->] (B1) at (5,0) {5};
        \node[circle, draw, fill=green!30, visible on=<2->] (C1) at (6,1) {6};
        
        \node[circle, draw, visible on=<2->] (Ancestor) at (7,3.5) {};
    
        % Connect the nodes to the common ancestor with curved arrows
        \draw[<-, bend left, visible on=<2->] (A1) to (Ancestor);
        \draw[<-, bend left, visible on=<2->] (B1) to (Ancestor);
        \draw[<-, bend left, visible on=<2->] (C1) to (Ancestor);
        \draw[<-, bend right, visible on=<2->] (D1) to (Ancestor);
        \draw[<-, bend right, visible on=<2->] (E1) to (Ancestor);
        \draw[<-, bend right, visible on=<2->] (F1) to (Ancestor);
    
        \draw[color=gray!50,line width=0.1mm, visible on=<2->] (A1) -- (B1);
        \draw[color=gray!50,line width=0.1mm, visible on=<2->] (B1) -- (C1);
        \draw[color=gray!50,line width=0.1mm, visible on=<2->] (C1) -- (A1);
        \draw[color=gray!50,line width=0.1mm, visible on=<2->] (D1) -- (E1);
        \draw[color=gray!50,line width=0.1mm, visible on=<2->] (E1) -- (F1);
        \draw[color=gray!50,line width=0.1mm, visible on=<2->] (F1) -- (D1);
        \draw[color=gray!50,line width=0.1mm, visible on=<2->] (F1) -- (C1);
        
        \node[align=center, visible on=<2->] at (6.5, -1.5) {\textbf{Global coordination}};
        \node[align=center, visible on=<2->] at (6.5, -2.5) {Adaptation to research purposes,\\ or shared culture (``disciplinary matrix'')\\$\bm{B}$};
    \end{tikzpicture}
\end{figure}
\end{frame}


\begin{frame}{The Ising model as an intermediate idealized model}    
    \begin{itemize}
        \item Atomic magnetic spins in a material can be in two states: $\uparrow$ (+1) or $\downarrow$ (-1).
        \item Magnetic spins prefer to be aligned to their neighbors ($\uparrow\uparrow$ or $\downarrow\downarrow$)
        \item Can local interactions between spins at the microscopic level lead to macroscopic alignment?
    \end{itemize}

    \begin{equation}
    \label{eq:ising}
    P(\{\sigma_i\}|J,\bm{B}) = \frac{1}{Z(J,\bm{B})} e^{-H(\{\sigma_i\},J,\bm{B})}, \text{ and } H = -\underbrace{\sum_{i,j} J w_{ij} \sigma_{i}\sigma_j}_{\substack{\text{local}\\\text{pairwise interactions}}}\underbrace{- \sum_i B_{C_i}\sigma_i}_{\substack{\text{external}\\\text{magnetic field}}}
\end{equation}

\vspace{1em}

\centering
\url{https://mattbierbaum.github.io/ising.js/}

\centering
\vspace{1em}
Inverse Ising problem: $P(J,J^\text{cit},\bm{B}|\{\sigma_i\})$
\end{frame}


\begin{frame}{Local coordination in multi-layered graphs}
    \begin{figure}[!h]
    \centering
\resizebox{0.5\textwidth}{!}{
\begin{tikzpicture}
    % Parallelogram for Layer 1 (very transparent gray with more skew)
    \filldraw[fill=gray!10, draw=none] 
    (-2,-0.5) -- (3,-0.5) -- (4,2.5) -- (-1,2.5) -- cycle;

    % Parallelogram for Layer 2 (very transparent gray with more skew)
    \filldraw[fill=gray!10, draw=none] 
    (-2,3) -- (3,3) -- (4,6) -- (-1,6) -- cycle;

    
    % Left graph (traditional)
    \node[circle, draw, fill=red!30] (A) at (0,0) {4};
    \node[circle, draw, fill=green!30] (B) at (2,0) {5};
    \node[circle, draw, fill=red!30] (C) at (1,2) {2};
    \node[circle, draw, fill=green!30] (D) at (3,2) {3};
    \node[circle, draw, fill=red!30] (F) at (-0.5,1) {1};

    \node (g) at (-2,1) {\Large $G$};


    \node[circle, draw, fill=red!30] (A1) at (0,3.5) {4};
    \node[circle, draw, fill=green!30] (B1) at (2,3.5) {5};
    \node[circle, draw, fill=red!30] (C1) at (1,5.5) {2};
    \node[circle, draw, fill=green!30] (D1) at (3,5.5) {3};
    \node[circle, draw, fill=red!30] (F1) at (-0.5,4.5) {1};

    \node (gcit) at (-2,4.5) {\Large $G^{\text{cit}}$};

    \draw (A) -- (B);
    \draw (C) -- (D);
    \draw (C) -- (F);

    \draw[color=gray!70,line width=0.5mm,dashed] (A) -- (A1);
    \draw[color=gray!70,line width=0.5mm,dashed] (B) -- (B1);
    \draw[color=gray!70,line width=0.5mm,dashed] (C) -- (C1);
    \draw[color=gray!70,line width=0.5mm,dashed] (D) -- (D1);
    \draw[color=gray!70,line width=0.5mm,dashed] (F) -- (F1);


    \draw[->] (C1) -- (A1);
    \draw[->] (F1) -- (A1);
    \draw[->] (D1) -- (B1);
    
\end{tikzpicture}
}
\caption{\textbf{Illustration of local coordination in multilayered social networks}. Nodes can be connected through different kinds of relationships (for instance, authors can be related via collaborations ($G$) or citations ($G^{\text{cit}}$)). %In this diagram, patterns of coordination are better explained by the directed graph at the top ($G^{\text{cit}}$): (1,2) have imitated (4), and (3) has imitated (5).
}
    \label{fig:multilayered}
\end{figure}
\end{frame}

\begin{frame}{Local versus global coordination}
\begin{table}[h]
\centering
\caption{Parameters of the Ising model.}
\label{table:ising}
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{fit.pdf}
    \caption{Ising model fit}
\end{figure}
% \resizebox{\textwidth}{!}{
% \begin{tabular}{lcccc}
% \toprule
%  & Effect size & CI$_{\text{95\%}}$ & Effect size & CI$_{\text{95\%}}$ \\
% Parameter &  &  &  &  \\
% \midrule
% $J$ & +0.013 & [+0.009, \ +0.017] & +0.0095 & [+0.0052, \ +0.014] \\
% $J^{\mathrm{cit}}$ & - & - & +0.00049 & [+0.00023, \ +0.00075] \\
% $B(\mathrm{hep-ph})$ & -0.86 & [-0.99, \ -0.73] & -0.77 & [-0.91, \ -0.64] \\
% $B(\mathrm{hep-th})$ & -0.22 & [-0.29, \ -0.15] & -0.17 & [-0.24, \ -0.095] \\
% $B(\mathrm{gr-qc})$ & +0.075 & [-0.0069, \ +0.16] & +0.076 & [-0.0066, \ +0.16] \\
% $B(\mathrm{astro})$ & -0.6 & [-0.74, \ -0.47] & -0.59 & [-0.73, \ -0.46] \\
% \bottomrule
% \end{tabular}
% }
\end{table}
\end{frame}

\begin{frame}{Local versus global coordination}
    What values of $\bm{J}$ and $\bm{B}$ do our models predict? In other words, what is the probability $\textcolor{blue}{P(J,J^\text{cit},\bm{B}|M_i)}$ for each model $M_i$?
    \begin{figure}
        \centering
        \includegraphics[width=0.9\linewidth]{draws_compact_nobars.pdf}
    \end{figure}
\end{frame}

\begin{frame}{Local versus global coordination}
    Given $\textcolor{blue}{P(J,J^\text{cit},\bm{B}|M_i)}$, and the true values of $\bm{J}$ and $\bm{B}$, what is $\textcolor{red}{P(M_i|J,J^{\text{cit}},\bm{B}})$?

    After a bit of computational trickery -- ``amortized simulation-based model comparison with neural networks'' with BayesFlow --:
    
    \begin{figure}
        \centering
        \includegraphics[width=0.9\linewidth]{draws_compact.pdf}
    \end{figure}
\end{frame}

\begin{frame}{Challenges for model selection}
    \begin{itemize}
        \item<1-> Model misspecification: model comparison among highly incorrect models is challenging/meaningless
        \item<2-> Priors on models' parameter matter. A model is disadvantaged if it only is a good fit to the data for improbable parameter values.
    \end{itemize}
\end{frame}


\begin{frame}{Summary: inverse problems in practice}
\begin{enumerate}
    \item What \textbf{phenomenon}? (Belief-polarization? Discrimination and marginalization? etc.)
    \item What \textbf{model\underline{s}}? (``model-space'')
    \item What \textbf{data}?
    \begin{itemize}
        \item Accessibility (reasonable time/financial cost)
        \item Quality (bias? ecological validity?)
        \item Quantity (statistical significance)
    \end{itemize}
    \item What \textbf{computational strategies}?
    \begin{itemize}
        \item \textbf{Pre-processing}: e.g. text-classification (natural language processing)?
        \item \textbf{Inference} (inverse problem): simulation-based inference (with/without neural networks); Hamiltonian Monte-Carlo? Metropolis?
    \end{itemize}
\end{enumerate}
\end{frame}


\begin{frame}[allowframebreaks]{Thank you!}
    \nocite{Cranmer2020,radev2021amortized}
    \printbibliography[heading=none]
\end{frame}

\begin{frame}{Amortized simulation-based inference}
    \begin{itemize}
        \item Even with summary statistics, simulation-based inference is difficult because no simulated sample will \textit{exactly} match the observed data.
        \item Solution:
        \begin{itemize}
            \item<2-> Use amortized inference with neural networks $\Rightarrow$ train a neuralnet to predict the probability of each model $M_i$ given one or more observed outcomes. The neuralnet is trained with many simulated training samples $(M_s, O_s)$ \citep{radev2021amortized}
        \end{itemize}
    \end{itemize}
    \only<3>{
        \centering
        \begin{figure}
            \centering
            \includegraphics[width=0.9\linewidth]{amortized/frame_0.pdf}
        \end{figure}
    }
    \only<4>{
        \centering
        \begin{figure}
            \centering
            \includegraphics[width=0.9\linewidth]{amortized/frame_1.pdf}
        \end{figure}
    }
    \only<5>{
        \centering
        \begin{figure}
            \centering
            \includegraphics[width=0.9\linewidth]{amortized/frame_2.pdf}
        \end{figure}
    }
    \only<6>{
        \centering
        \begin{figure}
            \centering
            \includegraphics[width=0.9\linewidth]{amortized/frame_3.pdf}
        \end{figure}
    }
    \only<7>{
        \centering
        \begin{figure}
            \centering
            \includegraphics[width=0.9\linewidth]{amortized/frame_4.pdf}
        \end{figure}
    }
\end{frame}

\end{document}